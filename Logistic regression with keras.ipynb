{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"http://ml-school.uni-koeln.de\">Summer School \"Deep Learning for\n",
    "    Language Analysis\"</a> <br/><strong>Text Analysis with Deep Learning</strong><br/>Sep 5 - 9, 2022<br/>Nils Reiter<br/><a href=\"mailto:nils.reiter@uni-koeln.de\">nils.reiter@uni-koeln.de</a></div>\n",
    "    \n",
    "# Logistic regression with keras\n",
    "\n",
    "For warming up, let's look at a very simple example on how to do logistic regression with keras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate some random training data. The data set consists of 200 integer numbers, some of them below zero, some above. To use logistic regression, we create a binary classification task by assigning the numbers below zero to one class, the numbers above to the other. This is a very easy task, because we can already formulate a rule for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array(random.choices(range(-10,0), k=100) + random.choices(range(0,10), k=100))\n",
    "y_train = np.array([1 for i in range(100)] + [0 for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is optional. To enable it, replace 'False' by 'True'. The idea behind this step is to pollute the data set a little bit by adding 10 random numbers with random assignments to the data. After this, it is no longer always true, that numbers below 0 are in one class and above in the other. But the vast majority is still of this form, so the model should pick up the general trend.\n",
    "\n",
    "In any case, we can inspect the x values to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4,  -6,  -1,  -5,  -8,  -5,  -1,  -1, -10,  -9,  -2,  -4,  -8,\n",
       "       -10,  -8,  -4,  -8,  -1,  -7,  -1,  -4,  -8,  -5, -10,  -1,  -4,\n",
       "        -9, -10,  -4,  -1,  -1,  -6,  -5,  -5,  -3,  -4,  -6,  -5,  -4,\n",
       "        -2,  -1,  -7, -10,  -9,  -5,  -3,  -9,  -1,  -3,  -2,  -5,  -8,\n",
       "        -6,  -7,  -1,  -2, -10,  -4,  -6,  -8,  -9,  -5,  -8,  -6,  -8,\n",
       "        -8,  -8,  -2,  -4,  -3,  -2, -10, -10,  -2,  -5,  -1,  -1,  -9,\n",
       "        -2,  -6,  -2,  -1,  -3,  -3, -10,  -9,  -7,  -1,  -7,  -4,  -9,\n",
       "        -7, -10,  -1,  -1,  -9, -10,  -4,  -8,  -8,   9,   9,   5,   1,\n",
       "         1,   1,   9,   0,   8,   2,   4,   6,   8,   5,   5,   3,   5,\n",
       "         1,   0,   6,   9,   8,   8,   8,   7,   8,   0,   5,   4,   1,\n",
       "         9,   4,   0,   2,   6,   4,   2,   4,   5,   8,   3,   8,   0,\n",
       "         8,   4,   9,   2,   0,   7,   3,   7,   2,   8,   7,   2,   0,\n",
       "         8,   2,   9,   2,   9,   4,   8,   5,   6,   8,   6,   0,   1,\n",
       "         7,   4,   7,   5,   5,   7,   1,   8,   3,   3,   6,   8,   2,\n",
       "         6,   3,   6,   8,   2,   8,   0,   8,   4,   2,   4,   1,   9,\n",
       "         3,   9,   0,   0,   2,   7,   5,   9,   2, -10,  -9,   8,  -5,\n",
       "         3, -10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    x_train = np.append(x_train, random.choices(range(-10,10), k=10))\n",
    "    y_train = np.append(y_train, random.choices([0,1], k=10))\n",
    "    \n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step creates a neural network, consisting of 1 single neuron with \"sigmoid\" as an activation function. This is thus the same as doing logistic regression.\n",
    "\n",
    "Some more details:\n",
    "- We will always use the [sequential](https://keras.io/guides/sequential_model/) way of describing model architectures. There is another, somewhat more expressive way, the [functional](https://keras.io/guides/functional_api/) api. You might stumble upon examples in this notation on the internet.\n",
    "- In the exercises and examples, I always use `layers.Input(...)` as a first layer. This is not necessary, as the input shape can also be specified in the first \"real\" layer, with the argument `input_shape`. See documentation on the [input layer](https://keras.io/api/layers/core_layers/input/) for more details.\n",
    "- Models always need to be compiled before training. Thus, creating a model always consists of three steps:\n",
    "  1. Definition of the architecture (with a couple of `model.add(...)` commands), \n",
    "  2. Compiling the model. In this step, we also specify the loss function to use, and metrics to be displayed during training.\n",
    "  3. Fitting (i.e., training) the model. For this, we supply a few more arguments.\n",
    "- Getting the shape of the data right is not always trivial. To simplify development, one can always ask the model (with the current architecture) for its input and output shapes. This is done with the attributes `input_shape` and `output_shape`, respectively. See below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output shape is: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(1,)))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "print(\"The output shape is: \" + str(model.output_shape))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value of the `fit(...)`-function is the training history. We will not be using this extensively in this course, but it offers machine-readable information on the epochs. Feel free to inspect the history object at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 576us/step - loss: 0.0590 - accuracy: 0.9667\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 811us/step - loss: 0.0574 - accuracy: 0.9762\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 800us/step - loss: 0.0560 - accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 850us/step - loss: 0.0547 - accuracy: 0.9762\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 872us/step - loss: 0.0536 - accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9762\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 989us/step - loss: 0.0509 - accuracy: 0.9762\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 892us/step - loss: 0.0501 - accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 879us/step - loss: 0.0493 - accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 5, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a trained model, we can evaluate it by supplying test x and y data. In the following line, `[-3,5]` is an array of two test x values, `[1,0]` is the expected output. Of course, the input given here needs to be of the correct shape. More information on the `evaluate(...)` function can be found [here](https://keras.io/api/models/model_training_apis/#evaluate-method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0034 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003397827036678791, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([-3,5],[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can also use the `predict(...)` function to generate new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9967976 ],\n",
       "       [0.00124964]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5882695 ],\n",
       "       [0.38426894]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
