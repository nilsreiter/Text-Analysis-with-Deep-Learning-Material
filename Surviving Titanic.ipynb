{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"http://ml-school.uni-koeln.de\">Summer School \"Deep Learning for\n",
    "    Language Analysis\"</a> <br/><strong>Text Analysis with Deep Learning</strong><br/>Sep 5 - 9, 2022<br/>Nils Reiter<br/><a href=\"mailto:nils.reiter@uni-koeln.de\">nils.reiter@uni-koeln.de</a></div>\n",
    "\n",
    "\n",
    "# Feedforward Neural Network: Titanic\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"float:left;margin-right:10px;\"><img src=\"gfx/titanic.jpg\" width=\"200\" /></div> This dataset contains information about the titanic passengers, including names, gender, passenger class and whether they survived <a href=\"https://en.wikipedia.org/wiki/Sinking_of_the_Titanic\">the sinking of the ship</a>. \n",
    "\n",
    "We will use the data set to train a feedforward neural network that predicts — given the other information — whether someone survived. It is therefore a binary classification with the two classes \"survived\" (encoded as 1) and \"drowned\" (encoded as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "\n",
    "# fast matrices and array (much faster than regular python)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# generic machine learning utility functions\n",
    "\n",
    "# what we need for deep learning\n",
    "from tensorflow.python.keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# read the data from a CSV file (included in the repository)\n",
    "df = pd.read_csv(\"data/titanic/train.csv\")\n",
    "\n",
    "# show the table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns that we do not want to use as features, because they allow no generalization: `Name` and `PassengerId` can not be expected to contribute useful information to the survival of the passenger. We therefore drop the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Name\", 1)\n",
    "df = df.drop(\"PassengerId\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks generally expect numeric input. We therefore convert all non-numeric columns (`Sex`, `Cabin`, `Ticket` and `Embarked`) to numeric columns. This is done with [the pandas function `factorize()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.factorize.html). The function returns a tuple, and the numeric values are the first part. We therefore assign these as values for the respective columns. \n",
    "\n",
    "(It is not strictly necessary to wrap this into a function.)\n",
    "\n",
    "After calling the function, we again inspect the table to verify that this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_numeric(df):\n",
    "  df[\"Sex\"] = pd.factorize(df[\"Sex\"])[0]\n",
    "  df[\"Cabin\"] = pd.factorize(df[\"Cabin\"])[0]\n",
    "  df[\"Ticket\"] = pd.factorize(df[\"Ticket\"])[0]\n",
    "  df[\"Embarked\"] = pd.factorize(df[\"Embarked\"])[0]\n",
    "  return df\n",
    "\n",
    "df = make_numeric(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're looking closely, you might have seen that some rows contain NaN (= \"not a number\") or missing values. To remove these, we use the [pandas function `dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split up the data into the feature values (`x`) and the correct class labels (`y`). In this case, this is straightforward, because all we need is to extract one column and assign it to `y`. For `x`, we simply remove the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Survived\"]\n",
    "x = df.drop(\"Survived\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test\n",
    "\n",
    "For splitting the data into train and test, we make use of the [scikit-learn-function `train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). This is actually the only function from scikit-learn that we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the neural network\n",
    "\n",
    "We create a simple neural network here, consisting of one hidden layer with 50 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = models.Sequential()\n",
    "ffnn.add(layers.Input(shape=(9,)))\n",
    "ffnn.add(layers.Dense(50, activation=\"sigmoid\"))\n",
    "ffnn.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "ffnn.compile(loss=\"mean_squared_error\", \n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "ffnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start the training process, using [the `fit()`-function from keras](https://keras.io/api/models/model_training_apis/#fit-method). The function takes feature values (`x`), correct outcomes (`y`), and three more parameters to control the number of `epochs` and the `batch_size`. `verbose` controls the amount of output that is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ffnn.fit(x_train.to_numpy(), y_train.to_numpy(), epochs=10, batch_size=3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
