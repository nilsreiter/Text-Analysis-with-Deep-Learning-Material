{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><a href=\"http://ml-school.uni-koeln.de\">Summer School \"Deep Learning for\n",
    "    Language Analysis\"</a> <br/><strong>Text Analysis with Deep Learning</strong><br/>Sep 5 - 9, 2022<br/>Nils Reiter<br/><a href=\"mailto:nils.reiter@uni-koeln.de\">nils.reiter@uni-koeln.de</a></div>\n",
    "\n",
    "# Exercise 0: Getting Started\n",
    "\n",
    "This is the first exercise for you to solve independently, but as a group of approximately three students. Feel free to ask us for support. \n",
    "\n",
    "## The Task\n",
    "\n",
    "Each neural network is trained to solve one or more specific task(s). You can think of a task as a function that takes an input and generates an output. Ideally, the output depends on the input. The network in this exercise solves a very simple task: Assuming our input consists of sequences of ones and zeros, we want the network to also produce output consisting of ones and zeros -- but shifted by two positions. I.e., the input `[0,1,0,0]` results in\n",
    "`[0,0,0,1]` as output.\n",
    "\n",
    "This is obviously a trivial task, and even with moderate python skills, we can write a function that solves the task. Nevertheless, we will use a neural network to solve this task -- and in fact, we will use such a function to generate training data. But first, let's import the relevant libraries (and verify that they can be imported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "\n",
    "# limit GPU memory to 4 GB\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to define the basic settings for any task in variables. This way, they can be easily changed, even if they are used in multiple places in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of sequences to generate\n",
    "number_of_sequences = 40\n",
    "\n",
    "# The number of symbols to distinguish\n",
    "number_of_symbols = 2\n",
    "\n",
    "# The length of each sequence\n",
    "length_of_sequences = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# create the sequences randomly\n",
    "x_train = np.array([rng.integers(0,number_of_symbols,length_of_sequences) for i in range(number_of_sequences)])\n",
    "\n",
    "# show them\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical background\n",
    "(you may skip this if you're relatively new to Python)\n",
    "\n",
    "This (`x_train`) is actually a single object -- a [numpy](https://numpy.org) array. Despite their name, numpy arrays are multidimensional data structures and are used extensively in deep learning. The numpy array we have generated is a actually a two-dimensional array (i.e. a matrix). You can find out how many dimensions a numpy array has by asking its property [`ndim`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.ndim.html) (e.g., `x_train.ndim`). You can also find out how large each dimension is by asking the property [`shape`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.shape.html) (e.g., `x_train.shape`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have created the input training data, which are often labeled `x`. What we also need is the output training data, i.e., the shifted sequences. Output sequences are usually labeled `y`, such that the neural network can be thought of as a function that goes from $x$ to $y$: $f(x) = y$.\n",
    "\n",
    "This of course is the place where we already solve the task, using splicing and list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 0 1 1 1 1 0 0]\n",
      "[0 0 1 1 0 1 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([np.insert(x_seq[:length_of_sequences-2],0,[0,0]) for x_seq in x_train])\n",
    "\n",
    "# shifting should be visible here:\n",
    "print(x_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, the input sequences consist of scalar integers. Neural networks expect the elements to be vectors -- to allow including multiple features (e.g., from an embedding). We will therefore [`reshape`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) the ndimensional arrays we have. This is also a function that numpy provides.\n",
    "\n",
    "The result of this operation is that each sequence contains one-dimensional vectors instead of scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(40, length_of_sequences, 1)\n",
    "y_train = y_train.reshape(40, length_of_sequences, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "The next block defines the neural network we will be using. Don't worry, you will understand what you are doing later this week.\n",
    "\n",
    "Keras, the library that we are using, offers two APIs to specify a neural network: The [*Sequential API*](https://keras.io/guides/sequential_model/) and the [*Functional* API](https://keras.io/guides/functional_api/). We will be using the sequential API for the moment. Sequential here means that \"network\" is actually only a single lane: The output of one node goes as input into the next. The functional API allows more complex architectures and will be used later on.\n",
    "\n",
    "The last line of the block generates an overview of the network architecture that we have assembled. This is very handy, because complex architectures are ... complex. The middle column in this table contains the output shape of each layer. The last layer (last row) thus generates sequences of length 15, consisting of one-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 15, 10)            70        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15, 1)             11        \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "# define an input layer\n",
    "model.add(layers.InputLayer(input_shape=(length_of_sequences,1)))\n",
    "\n",
    "# define a hidden layer\n",
    "model.add(layers.Bidirectional(layers.SimpleRNN(5,return_sequences=True)))\n",
    "\n",
    "# define an output layer\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The actual training is done using the [`fit()`](https://keras.io/api/models/model_training_apis/) function, provided by keras. We will talk about each of the parameters, but feel free to play around with them.\n",
    "\n",
    "In any case, the function needs the input and output data to train on ($x$, `x_train` and $y$, `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 2.1926 - accuracy: 0.4700\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1008 - accuracy: 0.5167\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.6167\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6433\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6767\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.6933\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7100\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7300\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7633\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7950\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8183\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8367\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8567\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8717\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8850\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8883\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8917\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8983\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.9017\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.9150\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9283\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2411 - accuracy: 0.9417\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2284 - accuracy: 0.9433\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9517\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9517\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1946 - accuracy: 0.9583\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9667\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9667\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9717\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9750\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9817\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9867\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9883\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9867\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9900\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9917\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9917\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9933\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9967\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9967\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9967\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9967\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9967\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9967\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9967\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9967\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9967\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9967\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9967\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9967\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e959610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application and Testing\n",
    "\n",
    "Finally, we can use the trained model to predict a new sequence, using the `predict()` function. The predict function expects us to provide data that is structurally similar to the training data -- i.e., it should have the same dimensionality etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 1 0 -0.05330883\n",
      "01 0 0 -0.25208867\n",
      "02 0 1 1.5137744\n",
      "03 1 0 -0.43100852\n",
      "04 0 0 -0.66855615\n",
      "05 0 1 1.4111977\n",
      "06 0 0 -0.046335146\n",
      "07 1 0 -0.62494653\n",
      "08 0 0 -0.60186344\n",
      "09 0 1 1.3038105\n",
      "10 0 0 -0.53792495\n",
      "11 0 0 -1.0049039\n",
      "12 0 0 -0.67612857\n",
      "13 0 0 -0.48061174\n",
      "14 0 0 -0.65284264\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([[1,0,0,1,0,0,0,1,0,0,0,0,0,0,0]]).reshape(1,length_of_sequences,1)\n",
    "y_test = np.array([np.insert(x_seq[:length_of_sequences-2],0,[0,0]) for x_seq in x_test])\n",
    "y_prediction = model.predict(x_test)\n",
    "y_prediction = y_prediction.reshape(length_of_sequences)\n",
    "\n",
    "for i in range(length_of_sequences):\n",
    "    print(f\"{i:02d}\", end=\" \")\n",
    "    print(x_test[0][i][0], end=\" \")\n",
    "    print(y_test[0][i], end=\" \")\n",
    "    print(y_prediction[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
